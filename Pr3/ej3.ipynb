{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargar el corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP Confidence/NN)\n",
      "  (PP in/IN)\n",
      "  (NP the/DT pound/NN)\n",
      "  (VP is/VBZ widely/RB expected/VBN to/TO take/VB)\n",
      "  (NP another/DT sharp/JJ dive/NN)\n",
      "  if/IN\n",
      "  (NP trade/NN figures/NNS)\n",
      "  (PP for/IN)\n",
      "  (NP September/NNP)\n",
      "  ,/,\n",
      "  due/JJ\n",
      "  (PP for/IN)\n",
      "  (NP release/NN)\n",
      "  (NP tomorrow/NN)\n",
      "  ,/,\n",
      "  (VP fail/VB to/TO show/VB)\n",
      "  (NP a/DT substantial/JJ improvement/NN)\n",
      "  (PP from/IN)\n",
      "  (NP July/NNP and/CC August/NNP)\n",
      "  (NP 's/POS near-record/JJ deficits/NNS)\n",
      "  ./.)\n",
      "[('Rockwell', 'NNP', 'B-NP'), ('International', 'NNP', 'I-NP'), ('Corp.', 'NNP', 'I-NP'), (\"'s\", 'POS', 'B-NP'), ('Tulsa', 'NNP', 'I-NP'), ('unit', 'NN', 'I-NP'), ('said', 'VBD', 'B-VP'), ('it', 'PRP', 'B-NP'), ('signed', 'VBD', 'B-VP'), ('a', 'DT', 'B-NP'), ('tentative', 'JJ', 'I-NP'), ('agreement', 'NN', 'I-NP'), ('extending', 'VBG', 'B-VP'), ('its', 'PRP$', 'B-NP'), ('contract', 'NN', 'I-NP'), ('with', 'IN', 'B-PP'), ('Boeing', 'NNP', 'B-NP'), ('Co.', 'NNP', 'I-NP'), ('to', 'TO', 'B-VP'), ('provide', 'VB', 'I-VP'), ('structural', 'JJ', 'B-NP'), ('parts', 'NNS', 'I-NP'), ('for', 'IN', 'B-PP'), ('Boeing', 'NNP', 'B-NP'), (\"'s\", 'POS', 'B-NP'), ('747', 'CD', 'I-NP'), ('jetliners', 'NNS', 'I-NP'), ('.', '.', 'O')]\n"
     ]
    }
   ],
   "source": [
    "import nltk.chunk\n",
    "import nltk\n",
    "from nltk.corpus import conll2000\n",
    "\n",
    "# Cargar conjunto de entrenamiento y pruebas, en formato conlleval (árbol de etiquetas)\n",
    "conll_train = conll2000.chunked_sents('train.txt')\n",
    "conll_test = conll2000.chunked_sents('test.txt')\n",
    "print(conll_train[0])\n",
    "\n",
    "# Convertir los arboles de etiquetas a lista de listas con etiquetas\n",
    "train_chunks = [nltk.chunk.tree2conlltags(tree) for tree in conll_train]\n",
    "test_chunks = [nltk.chunk.tree2conlltags(tree) for tree in conll_test]\n",
    "\n",
    "# Datos de entrenamiento y pruebas para los chunkers en forma de lista con etiquitas IOB\n",
    "train=[[(t, c) for (w, t, c) in chunk_tags] for chunk_tags in train_chunks]\n",
    "test= [[(t, c) for (w, t, c) in chunk_tags] for chunk_tags in test_chunks]\n",
    "\n",
    "\n",
    "print(test_chunks[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargar etiquetador de la Pr2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Confidence', 'NN'), ('in', 'IN'), ('the', 'DT'), ('pound', 'NN'), ('is', 'VBZ'), ('widely', 'RB'), ('expected', 'VBN'), ('to', 'TO'), ('take', 'VB'), ('another', 'DT'), ('sharp', 'JJ'), ('dive', 'NN'), ('if', 'IN'), ('trade', 'NN'), ('figures', 'NNS'), ('for', 'IN'), ('September', 'NNP'), (',', ','), ('due', 'JJ'), ('for', 'IN'), ('release', 'NN'), ('tomorrow', 'NN'), (',', ','), ('fail', 'VB'), ('to', 'TO'), ('show', 'VB'), ('a', 'DT'), ('substantial', 'JJ'), ('improvement', 'NN'), ('from', 'IN'), ('July', 'NNP'), ('and', 'CC'), ('August', 'NNP'), (\"'s\", 'POS'), ('near-record', 'JJ'), ('deficits', 'NNS'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "# Cargar frases para entrenar el tagger\n",
    "tagger_train_sentences = train_chunks\n",
    "for i in range(len(tagger_train_sentences)):\n",
    "    tagger_train_sentences[i] = [(w, t) for (w, t, c) in tagger_train_sentences[i]]\n",
    "\n",
    "print(tagger_train_sentences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Confidence', 'NN'), ('in', 'IN'), ('the', 'DT'), ('pound', 'NN'), ('is', 'VBZ'), ('widely', 'RB'), ('expected', 'VBN'), ('to', 'TO'), ('take', 'VB'), ('another', 'DT'), ('sharp', 'JJ'), ('dive', 'NN'), ('if', 'IN'), ('trade', 'NN'), ('figures', 'NNS'), ('for', 'IN'), ('September', 'NNP'), (',', ','), ('due', 'JJ'), ('for', 'IN'), ('release', 'NN'), ('tomorrow', 'NN'), (',', ','), ('fail', 'VB'), ('to', 'TO'), ('show', 'VB'), ('a', 'DT'), ('substantial', 'JJ'), ('improvement', 'NN'), ('from', 'IN'), ('July', 'NNP'), ('and', 'CC'), ('August', 'NNP'), (\"'s\", 'POS'), ('near-record', 'JJ'), ('deficits', 'NNS'), ('.', '.')]\n",
      "[('Confidence', 'NN'), ('in', 'IN'), ('the', 'DT'), ('pound', 'NN'), ('is', 'VB'), ('widely', 'RB'), ('expected', 'VB'), ('to', 'TO'), ('take', 'VB'), ('another', 'DT'), ('sharp', 'JJ'), ('dive', 'NN'), ('if', 'IN'), ('trade', 'NN'), ('figures', 'NN'), ('for', 'IN'), ('September', 'NN'), (',', ','), ('due', 'JJ'), ('for', 'IN'), ('release', 'NN'), ('tomorrow', 'NN'), (',', ','), ('fail', 'VB'), ('to', 'TO'), ('show', 'VB'), ('a', 'DT'), ('substantial', 'JJ'), ('improvement', 'NN'), ('from', 'IN'), ('July', 'NN'), ('and', 'CC'), ('August', 'NN'), (\"'s\", 'PO'), ('near-record', 'JJ'), ('deficits', 'NN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "tagger_train_sentences_simplified = []\n",
    "for sentence in tagger_train_sentences:\n",
    "    new_sentence = []\n",
    "    \n",
    "    for taged_word in sentence:\n",
    "        word, tag = taged_word\n",
    "        main_category = tag[0]\n",
    "\n",
    "        if word == '*0*':\n",
    "            continue\n",
    "\n",
    "        match main_category:\n",
    "            case 'v':   # verbo\n",
    "                new_tag = tag[:3]\n",
    "            case 'F':   # signo de puntuación\n",
    "                new_tag = tag[:3]\n",
    "            case _:     # otro\n",
    "                new_tag = tag[:2]\n",
    "\n",
    "        new_sentence.append((word, new_tag))\n",
    "\n",
    "    tagger_train_sentences_simplified.append(new_sentence)\n",
    "\n",
    "print(tagger_train_sentences[0])\n",
    "print(tagger_train_sentences_simplified[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tag import hmm\n",
    "tagger_hmm = hmm.HiddenMarkovModelTagger.train(tagger_train_sentences_simplified)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etiquetar y formatear la salida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Etiquetar el test\n",
    "test_sentences = [[(w, t) for (w, t, c) in sentence] for sentence in test_chunks]\n",
    "tagged_test_sentences = [tagger_hmm.tag(sentence) for sentence in test_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('NNP', 'B-NP'), None),\n",
       " (('VBD', 'B-VP'), None),\n",
       " (('DT', 'B-NP'), None),\n",
       " (('NN', 'I-NP'), None),\n",
       " (('VBZ', 'B-VP'), None),\n",
       " (('IN', 'O'), None),\n",
       " (('PRP', 'B-NP'), None),\n",
       " (('TO', 'B-VP'), None),\n",
       " (('VB', 'I-VP'), None),\n",
       " (('CD', 'B-NP'), None),\n",
       " (('JJ', 'I-NP'), None),\n",
       " (('JJ', 'I-NP'), None),\n",
       " (('NNS', 'I-NP'), None),\n",
       " (('IN', 'B-PP'), None),\n",
       " (('DT', 'B-NP'), None),\n",
       " (('NNS', 'I-NP'), None),\n",
       " (('.', 'O'), None)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunker = nltk.tag.UnigramTagger(train)\n",
    "chunker.tag(test[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formatear la salida del test\n",
    "output_lines = []\n",
    "for i, sentence in enumerate(test_chunks): # para cada frase\n",
    "    for j, (word, pos, gold_chunk) in enumerate(sentence): # para cada palabra\n",
    "        pred_chunk = tagged_test_sentences[i][j][1]\n",
    "        output_lines.append(f\"{word} {pos} {gold_chunk} {pred_chunk}\")\n",
    "    output_lines.append(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar la salida en un archivo\n",
    "with open(\"test_output.txt\", \"w\") as f:\n",
    "    f.write(\"\\n\".join(output_lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\FX607\\Desktop\\Master\\LC\\Pr3\\conlleval.py\", line 235, in <module>\n",
      "    evaluate_conll_file(sys.stdin)\n",
      "  File \"c:\\Users\\FX607\\Desktop\\Master\\LC\\Pr3\\conlleval.py\", line 229, in evaluate_conll_file\n",
      "    return evaluate(true_seqs, pred_seqs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\FX607\\Desktop\\Master\\LC\\Pr3\\conlleval.py\", line 209, in evaluate\n",
      "    correct_counts, true_counts, pred_counts) = count_chunks(true_seqs, pred_seqs)\n",
      "                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\FX607\\Desktop\\Master\\LC\\Pr3\\conlleval.py\", line 131, in count_chunks\n",
      "    _, pred_type = split_tag(pred_tag)\n",
      "    ^^^^^^^^^^^^\n",
      "ValueError: not enough values to unpack (expected 2, got 1)\n"
     ]
    }
   ],
   "source": [
    "!python conlleval.py < test_output.txt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LC_nltk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
