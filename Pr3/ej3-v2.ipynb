{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP Confidence/NN)\n",
      "  (PP in/IN)\n",
      "  (NP the/DT pound/NN)\n",
      "  (VP is/VBZ widely/RB expected/VBN to/TO take/VB)\n",
      "  (NP another/DT sharp/JJ dive/NN)\n",
      "  if/IN\n",
      "  (NP trade/NN figures/NNS)\n",
      "  (PP for/IN)\n",
      "  (NP September/NNP)\n",
      "  ,/,\n",
      "  due/JJ\n",
      "  (PP for/IN)\n",
      "  (NP release/NN)\n",
      "  (NP tomorrow/NN)\n",
      "  ,/,\n",
      "  (VP fail/VB to/TO show/VB)\n",
      "  (NP a/DT substantial/JJ improvement/NN)\n",
      "  (PP from/IN)\n",
      "  (NP July/NNP and/CC August/NNP)\n",
      "  (NP 's/POS near-record/JJ deficits/NNS)\n",
      "  ./.)\n",
      "-------\n",
      "(S\n",
      "  (NP Rockwell/NNP International/NNP Corp./NNP)\n",
      "  (NP 's/POS Tulsa/NNP unit/NN)\n",
      "  (VP said/VBD)\n",
      "  (NP it/PRP)\n",
      "  (VP signed/VBD)\n",
      "  (NP a/DT tentative/JJ agreement/NN)\n",
      "  (VP extending/VBG)\n",
      "  (NP its/PRP$ contract/NN)\n",
      "  (PP with/IN)\n",
      "  (NP Boeing/NNP Co./NNP)\n",
      "  (VP to/TO provide/VB)\n",
      "  (NP structural/JJ parts/NNS)\n",
      "  (PP for/IN)\n",
      "  (NP Boeing/NNP)\n",
      "  (NP 's/POS 747/CD jetliners/NNS)\n",
      "  ./.)\n",
      "[('Rockwell', 'NNP', 'B-NP'), ('International', 'NNP', 'I-NP'), ('Corp.', 'NNP', 'I-NP'), (\"'s\", 'POS', 'B-NP'), ('Tulsa', 'NNP', 'I-NP'), ('unit', 'NN', 'I-NP'), ('said', 'VBD', 'B-VP'), ('it', 'PRP', 'B-NP'), ('signed', 'VBD', 'B-VP'), ('a', 'DT', 'B-NP'), ('tentative', 'JJ', 'I-NP'), ('agreement', 'NN', 'I-NP'), ('extending', 'VBG', 'B-VP'), ('its', 'PRP$', 'B-NP'), ('contract', 'NN', 'I-NP'), ('with', 'IN', 'B-PP'), ('Boeing', 'NNP', 'B-NP'), ('Co.', 'NNP', 'I-NP'), ('to', 'TO', 'B-VP'), ('provide', 'VB', 'I-VP'), ('structural', 'JJ', 'B-NP'), ('parts', 'NNS', 'I-NP'), ('for', 'IN', 'B-PP'), ('Boeing', 'NNP', 'B-NP'), (\"'s\", 'POS', 'B-NP'), ('747', 'CD', 'I-NP'), ('jetliners', 'NNS', 'I-NP'), ('.', '.', 'O')]\n",
      "----\n",
      "[('NN', 'B-NP'), ('IN', 'B-PP'), ('DT', 'B-NP'), ('NN', 'I-NP'), ('VBZ', 'B-VP'), ('RB', 'I-VP'), ('VBN', 'I-VP'), ('TO', 'I-VP'), ('VB', 'I-VP'), ('DT', 'B-NP'), ('JJ', 'I-NP'), ('NN', 'I-NP'), ('IN', 'O'), ('NN', 'B-NP'), ('NNS', 'I-NP'), ('IN', 'B-PP'), ('NNP', 'B-NP'), (',', 'O'), ('JJ', 'O'), ('IN', 'B-PP'), ('NN', 'B-NP'), ('NN', 'B-NP'), (',', 'O'), ('VB', 'B-VP'), ('TO', 'I-VP'), ('VB', 'I-VP'), ('DT', 'B-NP'), ('JJ', 'I-NP'), ('NN', 'I-NP'), ('IN', 'B-PP'), ('NNP', 'B-NP'), ('CC', 'I-NP'), ('NNP', 'I-NP'), ('POS', 'B-NP'), ('JJ', 'I-NP'), ('NNS', 'I-NP'), ('.', 'O')]\n",
      "====\n",
      "[('NNP', 'B-NP'), ('NNP', 'I-NP'), ('NNP', 'I-NP'), ('POS', 'B-NP'), ('NNP', 'I-NP'), ('NN', 'I-NP'), ('VBD', 'B-VP'), ('PRP', 'B-NP'), ('VBD', 'B-VP'), ('DT', 'B-NP'), ('JJ', 'I-NP'), ('NN', 'I-NP'), ('VBG', 'B-VP'), ('PRP$', 'B-NP'), ('NN', 'I-NP'), ('IN', 'B-PP'), ('NNP', 'B-NP'), ('NNP', 'I-NP'), ('TO', 'B-VP'), ('VB', 'I-VP'), ('JJ', 'B-NP'), ('NNS', 'I-NP'), ('IN', 'B-PP'), ('NNP', 'B-NP'), ('POS', 'B-NP'), ('CD', 'I-NP'), ('NNS', 'I-NP'), ('.', 'O')]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import conll2000\n",
    "conll_train = conll2000.chunked_sents('train.txt')\n",
    "conll_test = conll2000.chunked_sents('test.txt')\n",
    "print (conll_train[0])\n",
    "print (\"-------\")\n",
    "print (conll_test[0])\n",
    "\n",
    "import nltk.chunk\n",
    "train_chunks = [nltk.chunk.tree2conlltags(tree) for tree in conll_train]\n",
    "test_chunks= [nltk.chunk.tree2conlltags(tree) for tree in conll_test]\n",
    "print(test_chunks[0])\n",
    "\n",
    "\n",
    "train=[[(t, c) for (w, t, c) in chunk_tags] for chunk_tags in train_chunks]\n",
    "test= [[(t, c) for (w, t, c) in chunk_tags] for chunk_tags in test_chunks]\n",
    "print(\"----\")\n",
    "print(train[0])\n",
    "print(\"====\")\n",
    "print(test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.901513392574456\n",
      "[('Rockwell', 'NNP', 'B-NP'), ('International', 'NNP', 'I-NP'), ('Corp.', 'NNP', 'I-NP'), (\"'s\", 'POS', 'B-NP'), ('Tulsa', 'NNP', 'I-NP'), ('unit', 'NN', 'I-NP'), ('said', 'VBD', 'B-VP'), ('it', 'PRP', 'B-NP'), ('signed', 'VBD', 'B-VP'), ('a', 'DT', 'B-NP'), ('tentative', 'JJ', 'I-NP'), ('agreement', 'NN', 'I-NP'), ('extending', 'VBG', 'B-VP'), ('its', 'PRP$', 'B-NP'), ('contract', 'NN', 'I-NP'), ('with', 'IN', 'B-PP'), ('Boeing', 'NNP', 'B-NP'), ('Co.', 'NNP', 'I-NP'), ('to', 'TO', 'B-VP'), ('provide', 'VB', 'I-VP'), ('structural', 'JJ', 'B-NP'), ('parts', 'NNS', 'I-NP'), ('for', 'IN', 'B-PP'), ('Boeing', 'NNP', 'B-NP'), (\"'s\", 'POS', 'B-NP'), ('747', 'CD', 'I-NP'), ('jetliners', 'NNS', 'I-NP'), ('.', '.', 'O')]\n",
      "\n",
      "frase: ['NNP', 'NNP', 'NNP', 'POS', 'NNP', 'NN', 'VBD', 'PRP', 'VBD', 'DT', 'JJ', 'NN', 'VBG', 'PRP$', 'NN', 'IN', 'NNP', 'NNP', 'TO', 'VB', 'JJ', 'NNS', 'IN', 'NNP', 'POS', 'CD', 'NNS', '.']\n",
      "\n",
      "frase_etiquetada:  [('NNP', 'B-NP'), ('NNP', 'I-NP'), ('NNP', 'I-NP'), ('POS', 'B-NP'), ('NNP', 'I-NP'), ('NN', 'I-NP'), ('VBD', 'B-VP'), ('PRP', 'B-NP'), ('VBD', 'B-VP'), ('DT', 'B-NP'), ('JJ', 'I-NP'), ('NN', 'I-NP'), ('VBG', 'B-VP'), ('PRP$', 'B-NP'), ('NN', 'I-NP'), ('IN', 'B-PP'), ('NNP', 'B-NP'), ('NNP', 'I-NP'), ('TO', 'B-VP'), ('VB', 'I-VP'), ('JJ', 'B-NP'), ('NNS', 'I-NP'), ('IN', 'B-PP'), ('NNP', 'B-NP'), ('POS', 'B-NP'), ('CD', 'I-NP'), ('NNS', 'I-NP'), ('.', 'O')]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "chunker = nltk.tag.HiddenMarkovModelTagger.train(train)\n",
    "print ('accuracy:', chunker.accuracy(test))\n",
    "\n",
    "\n",
    "print (test_chunks[0])\n",
    "frase= [(t) for (w, t, c) in test_chunks[0]]\n",
    "print(\"\")\n",
    "print(\"frase:\",frase)\n",
    "print(\"\")\n",
    "print(\"frase_etiquetada: \",chunker.tag(frase))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formatear la salida del test\n",
    "output_lines = []\n",
    "\n",
    "for idx_sentence, sentence in enumerate(test_chunks): # para cada frase\n",
    "    pos_tags = [(t) for (w, t, c) in sentence]\n",
    "    pred_tags = [c for (t, c) in chunker.tag(pos_tags)]\n",
    "\n",
    "    for idx_word, (w, t, c) in enumerate(sentence): # para cada palabra\n",
    "        output_lines.append(f\"{w} {t} {c} {pred_tags[idx_word]}\")\n",
    "\n",
    "    output_lines.append(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar la salida en un archivo\n",
    "with open(\"test_output.txt\", \"w\") as f:\n",
    "    f.write(\"\\n\".join(output_lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 49388 tokens with 21891 phrases; found: 22758 phrases; correct: 19008.\n",
      "accuracy:  92.53%; (non-O)\n",
      "accuracy:  90.55%; precision:  83.52%; recall:  86.83%; FB1:  85.14\n",
      "               NP: precision:  83.76%; recall:  86.45%; FB1:  85.08  12821\n",
      "               PP: precision:  83.50%; recall:  92.16%; FB1:  87.62  5310\n",
      "               VP: precision:  82.88%; recall:  82.33%; FB1:  82.61  4627\n"
     ]
    }
   ],
   "source": [
    "!python conlleval.py < test_output.txt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LC_nltk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
